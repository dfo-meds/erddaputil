

[erddaputil]
## ERDDAPUtil can send messages to modify the ERDDAP configuration either via
## a local daemon (the default) and/or an AMPQ message queue. These messages are
## triggered by calling the CLI or the HTTP interface.

# Make sure this value is hard to guess and secret but the same between all servers
# It will be used to sign the messages passed to AMPQ and to the local
# server daemons to prevent malicious messages from being sent.
secret_key = ""

## Set this to false if you only want to use AMPQ to send messages.
## Make sure the values in [erddaputil.service] are set properly
# use_local_daemon = true

## Set this to true if you are going to use AMPQ to send messages
## Make sure the values in [erddaputil.ampq] are set properly.
# use_ampq_exchange = false

## Set this to a class that subclasses BaseThread (supports terminate() at least)
## and can support the send_message(metric) method from ScriptMetrics. The default
## is to not send metrics.
metrics_manager = "erddaputil.main.metrics.LocalPrometheusSendThread"


[erddaputil.localprom]
## Use these settings to specify how to connect to our custom
## pushgateway-esque tool.

## Host where our custom pushgateway lives
host = "localhost"

## Port we can connect to the pushgateway on
port = 5000

## Alternatively, specify the path to the endpoint here
## (defaults to http://HOST:PORT/push)
# metrics_path = ""

## Username for Basic auth
username = ""

## Password for Basic auth
password = ""

## Maximum number of simultaneous push tasks
# max_tasks = 5

## Maximum number of metric changes to push in one batch
# batch_size = 10

## Maximum number of seconds to wait for more metric changes
# batch_wait_seconds = 1

## Maximum number of times to retry pushing the metrics
# max_retries = 5

## Delay in between retries
# retry_delay_seconds = 15

## Delay in checking for new messages (sleep time)
# delay_seconds = 0.25


[erddaputil.erddap]
## Enter the path to your ERDDAP bigParentDirectory. If left blank, dataset reloads cannot be done.
big_parent_directory = ""

## Enter the path to a template file to use for your datasets.xml (or leave blank to use the default template)
datasets_xml_template = ""

## Enter the path to your datasets.d folder with dataset XML files within it. If left blank, certain
## operations are not available.
datasets_d = ""

## Enter the path to your datasets.xml file. If left blank, certain operations are not available.
datasets_xml = ""

## Enter the path to store backups of the datasets.xml file or leave blank to not have backups
backups = ""

## Uncomment these if you want to change the default locations
# subscription_block_list = ""          # Defaults to .email_block_list.txt in XML template directory
# ip_block_list = ""                    # Defaults to .ip_block_list.txt in XML template directory
# unlimited_allow_list = ""             # Defaults to .unlimited_allow_list.txt in XML directory


[erddaputil.dataset_manager]
## Maximum number of datasets that can be pending reload at once
# max_pending = 2

## Maxumum delay in seconds that a dataset will wait for additional reloads to be sent.
# max_delay_seconds = 10

## Maximum delay in seconds that a request to recompile will wait
# max_recompile_delay = 15

## If set to false, a poorly formed XML document will cause the recompile process to abort.
## Otherwise, the file is simply omitted and a warning emitted.
# skip_misconfigured_datasets = true

## Number of days to keep the backups
# backup_retention_days = 30

[erddaputil.service]
## Socket bind address for the ERDDAP management daemon
## You might need to override this if you use a containerized approach.
# host = "127.0.0.1"

## Socket bind port for the ERDDAP management daemon
# port = 7012

## Socket backlog of connections before new connections are rejected
# backlog = 20

## Time to wait for a new connection (note that a tidy up can be done at most this often)
# listen_block_seconds = 0.25

[erddaputil.logman]
## Set to false to disable the logman tool
# enabled = true

## Time in days to preserve log files
# retention_days = 31

## Time in seconds to wait between re-scanning the log directory
# sleep_time_seconds = 3600

## List of file prefixes to remove
# file_prefixes = ["logPreviousArchivedAt", "logArchivedAt", "emailLog"]

[erddaputil.ampq]
## If you are running multiple clusters, specify the cluster name here.
## The ERDDAP management daemon will only broadcast commands to its own cluster
# cluster_name = "default"

## Specify a host name for the current machine, which should be unique to this environment
## and persist through reboots.
## Leave it blank to use the machine's calculated hostname (i.e. socket.gethostname()).
## If you intend to use the CLI or HTTP interface on the server to trigger the AMPQ
## messages (i.e. with use_ampq_exchange = true on your servers), and you use containers
## to run the webapp/cli separately from the AMPQ daemon, make sure you set this explicitly.
# hostname = ""

## Specify the Pika URLParameters or Azure Service Bus connection string
connection = ""

## Specify the RabbitMQ Exchange Name or the Azure Service Bus Topic Name
## Note that this system does NOT attempt to create the exchange or topic
# exchange_name = "erddap_cnc"

## Specify if the system should attempt to create the queue (for RabbitMQ) or the
## subscription (for Azure Service Bus).
# create_queue = true

## Choose "pika" or "azure_service_bus" to control which client to use
implementation = "pika"



[erddaputil.webapp]
## Enable the metrics collector. In essence, this is like a local version of a pushgateway
# enable_metrics_collector = true

## Enable the management API.
# enable_management_api = true

## Specify a file where passwords can be stored. Mandatory if etiher the metrics collector
## or the management API is to be used, otherwise it can be blank.
password_file = ""

## Specify a list of peppers. Peppers should only be removed once all passwords have been
## changed that used it. Peppers are specified in order from most recent to least recentr.
peppers = [""]

## Specify the hash algorithm used.
# password_hash = "sha256"

## Specify the length of the salt used for new passwords.
# salt_length = 16

## Specify the minimum number of iterations for PBKDF2
# min_iterations = 700000

## If greater than 0, the number of iterations will vary by username by up to
## this amount
# iterations_jitter = 100000


## Flask-specific configuration for the webapp.
[flask]


## Logging settings below
[logging]
version = 1

[logging.root]
level = "INFO"
handlers = ["console"]

[logging.handlers.console]
class = "logging.StreamHandler"
formatter = "brief"
level = "INFO"
stream = "ext://sys.stdout"

[logging.formatters.brief]
format = "%(asctime)s [%(levelname)s] %(message)s"