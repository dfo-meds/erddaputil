[erddaputil]
## ERDDAPUtil can send messages to modify the ERDDAP configuration either via
## a local daemon (the default) and/or an AMPQ message queue. These messages are
## triggered by calling the CLI or the HTTP interface.

## Set to true to dump the configuration out on boot (with secrets obfuscated)
# show_config = false

# Make sure this value is hard to guess and secret but the same between all servers
# It will be used to sign the messages passed to AMPQ and to the local
# server daemons to prevent malicious messages from being sent.
secret_key = ""

## Set this to false if you only want to use AMPQ to send messages.
## Make sure the values in [erddaputil.service] are set properly
# use_local_daemon = true

## Set this to true if you are going to use AMPQ to send messages
## Make sure the values in [erddaputil.ampq] are set properly.
# use_ampq_exchange = false

## Set this to a class that subclasses BaseThread (supports terminate() at least)
## and can support the send_message(metric) method from ScriptMetrics. The default
## is to not send metrics.
metrics_manager = "erddaputil.main.metrics.LocalPrometheusSendThread"

## Set this to false to prevent ERDDAPUtil from doing a compile on startup
#compile_on_boot = true

## Set this to false to prevent ERDDAPUtil from overriding the default credentials
## on startup
#create_default_user_on_boot = true

## Credentials that are created by default on startup
#default_username = "admin"
#default_password = "admin"

## Set to false to not try to fix the ERDDAP's BPD permissions on boot
# fix_erddap_bpd_permissions = true

[erddaputil.erddap]
## Enter the path to your ERDDAP bigParentDirectory. If left blank, dataset reloads cannot be done.
big_parent_directory = ""

## Enter the path to a template file to use for your datasets.xml (or leave blank to use the default template)
datasets_xml_template = ""

## Enter the path to your datasets.d folder with dataset XML files within it. If left blank, certain
## operations are not available.
datasets_d = ""

## Enter the path to your datasets.xml file. If left blank, certain operations are not available.
datasets_xml = ""

## Enter the path to ERDDAP's home page (e.g. http://localhost:8080/erddap/)
base_url = ""

## Uncomment these if you want to change the default locations
# subscription_block_list = ""          # Defaults to .email_block_list.txt in XML template directory
# ip_block_list = ""                    # Defaults to .ip_block_list.txt in XML template directory
# unlimited_allow_list = ""             # Defaults to .unlimited_allow_list.txt in XML directory


[erddaputil.tomcat]
## If ERDDAPUtil is instructed to fix the ERDDAP server's BPD permissions on boot, these are the
## values used (defaults are from the Axiom Docker install of ERDDAP).
# uid = 1000
# gid = 1000

## Information about logging - this should match the configuration
## set for AccessLogValve in server.xml or context.xml for ERDDAP
# log_directory = ""
# log_prefix = "access_log"
# log_suffix = ""
# log_pattern = "common"
# log_encoding = "utf-8"

## The Tomcat major version being used - impacts how request times
## are parsed from log formats as Tomcat changed the units in v10.
# major_version = 10



[erddaputil.dataset_manager]
## Maximum number of datasets that can be pending reload at once
# max_pending = 0

## Maxumum delay in seconds that a dataset will wait for additional reloads to be sent.
# max_delay_seconds = 0

## Maximum delay in seconds that a request to recompile will wait
# max_recompile_delay_seconds = 0

## If set to false, a poorly formed XML document will cause the recompile process to abort.
## Otherwise, the file is simply omitted and a warning emitted.
# skip_misconfigured_datasets = true

## Enter the path to store backups of the datasets.xml file or leave blank to not have backups
backups = ""

## Number of days to keep the backups
# backup_retention_days = 31

[erddaputil.daemon]
## Socket connection address for the ERDDAP management daemon
## You might need to override this if you use a containerized approach.
# host = "127.0.0.1"

## Socket bind port for the ERDDAP management daemon
# port = 9172

[erddaputil.service]
## Socket bind address for the ERDDAP management daemon
## You might need to override this if you use a containerized approach.
# host = "127.0.0.1"

## Socket bind port for the ERDDAP management daemon
# port = 9172

## Socket backlog of connections before new connections are rejected
# backlog = 20

## Time to wait for a new connection (note that a tidy up can be done at most this often)
# listen_block_seconds = 0.25

[erddaputil.logman]
## Set to false to disable the logman tool
# enabled = true

## Time in days to preserve log files
# retention_days = 31

## Time in seconds to wait between re-scanning the log directory
# sleep_time_seconds = 3600

## List of file prefixes to remove for ERDDAP
# file_prefixes = ["logPreviousArchivedAt", "logArchivedAt", "emailLog"]

## Set to true to also prune tomcat access logs with the same rules
## Note that most versions of Tomcat can handle this for you.
# include_tomcat = false

## Set to false to not prune erddap logs
# include_erddap = true

## Set to false to not prune tomtail logs
# include_tomtail = true

[erddaputil.tomtail]
## Set to false to disable tomcat access log parsing
# enabled = true

## Override the default location of the memory file of tomcat logs (defaults to current
## working directory)
# memory_file = "./.tomtail.mem"

## Set this to an output directory to write output files.
# output_directory = ""

## Will be passed into datetime.datetime.now().strptime() to get the file.
# output_file_pattern = "erddap_access_log_%Y%m%d.log"

## Pattern to output, see documentation
# output_pattern = "%dataset_id %request_type %s %b %T \"%U%q\""

## Time to wait before starting another run (from start to start)
# sleep_time_seconds = 30

[erddaputil.ampq]
## If you are running multiple clusters, specify the cluster name here.
## The ERDDAP management daemon will only broadcast commands to its own cluster
# cluster_name = "default"

## Specify a host name for the current machine, which should be unique to this environment
## and persist through reboots.
## Leave it blank to use the machine's calculated hostname (i.e. socket.gethostname()).
## If you intend to use the CLI or HTTP interface on the server to trigger the AMPQ
## messages (i.e. with use_ampq_exchange = true on your servers), and you use containers
## to run the webapp/cli separately from the AMPQ daemon, make sure you set this explicitly.
# hostname = ""

## Specify the Pika URLParameters or Azure Service Bus connection string
connection = ""

## Specify the RabbitMQ Exchange Name or the Azure Service Bus Topic Name
## Note that this system does NOT attempt to create the exchange or topic
# exchange_name = "erddap_cnc"

## Specify if the system should attempt to create the queue (for RabbitMQ) or the
## subscription (for Azure Service Bus).
# create_queue = true

## Choose "pika" or "azure_service_bus" to control which client to use
implementation = "pika"



[erddaputil.webapp]
## Enable the metrics collector. In essence, this is like a local version of a pushgateway
# enable_metrics_collector = true

## Enable the management API.
# enable_management_api = true

## Specify a file where passwords can be stored. Mandatory if etiher the metrics collector
## or the management API is to be used, otherwise it can be blank.
password_file = ""

## Specify a list of peppers. Peppers should only be removed once all passwords have been
## changed that used it. Peppers are specified in order from most recent to least recentr.
peppers = [""]

## Specify the hash algorithm used.
# password_hash = "sha256"

## Specify the length of the salt used for new passwords.
# salt_length = 16

## Specify the minimum number of iterations for PBKDF2
# min_iterations = 700000

## If greater than 0, the number of iterations will vary by username by up to
## this amount
# iterations_jitter = 100000


[erddaputil.localprom]
## Use these settings to specify how to connect to our custom
## pushgateway-esque tool.

## Host where our custom pushgateway lives
host = "localhost"

## Port we can connect to the pushgateway on
port = 9173

## Alternatively, specify the path to the endpoint here
## (defaults to http://HOST:PORT/push)
# metrics_path = ""

## Username for Basic auth
username = ""

## Password for Basic auth
password = ""

## Maximum number of simultaneous push tasks
# max_tasks = 5

## Maximum number of metric changes to push in one batch
# batch_size = 200

## Maximum number of seconds to wait for more metric changes
# batch_wait_seconds = 2

## Maximum number of times to retry pushing the metrics
# max_retries = 3

## Delay in between retries
# retry_delay_seconds = 2


[erddaputil.status_scraper]

## Set to false to disable scraping the status page to Prometheus metrics
# enabled = true

## Set to the path of a file to store information about the last scrape of status.html
## Defaults to current working directory
# memory_path = "./.status_scrape.mem"

## Change the default time between scraps
# sleep_time_seconds = 300

## Change the time to wait after the daemon boots (defaults to 3 minutes)
## This lets ERDDAP boot before we start hitting it for status message updates
# start_delay_seconds = 180

## Flask-specific configuration for the webapp.
[flask]


## Logging settings below
[logging]
version = 1

[logging.root]
level = "INFO"
handlers = ["console"]

[logging.handlers.console]
class = "logging.StreamHandler"
formatter = "brief"
level = "INFO"
stream = "ext://sys.stdout"

[logging.formatters.brief]
format = "%(asctime)s [%(levelname)s] %(message)s"